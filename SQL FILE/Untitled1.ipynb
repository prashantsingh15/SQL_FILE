{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88779198",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 11-12: truncated \\UXXXXXXXX escape (1798790337.py, line 135)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 135\u001b[1;36m\u001b[0m\n\u001b[1;33m    with open('UserDetails\\UserDetails.csv' ,'a+') as csvFile:\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 11-12: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import tkinter as tk\n",
    "from tkinter import Message, Text\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import tkinter.ttk as ttk\n",
    "import tkinter.font as font\n",
    "from pathlib import Path\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"Face_Recogniser\")\n",
    "window.configure(background='white')\n",
    "window.grid_rowconfigure(0, weight=1)\n",
    "window.grid_columnconfigure(0, weight=1)\n",
    "message = tk.Label(\n",
    "\twindow, text=\"Face-Recognition-System\",\n",
    "\tbg=\"green\", fg=\"white\", width=50,\n",
    "\theight=3, font=('times', 30, 'bold'))\n",
    "\n",
    "message.place(x=200, y=20)\n",
    "\n",
    "lbl = tk.Label(window, text=\"No.\",\n",
    "\t\t\twidth=20, height=2, fg=\"green\",\n",
    "\t\t\tbg=\"white\", font=('times', 15, ' bold '))\n",
    "lbl.place(x=400, y=200)\n",
    "\n",
    "txt = tk.Entry(window,\n",
    "\t\t\twidth=20, bg=\"white\",\n",
    "\t\t\tfg=\"green\", font=('times', 15, ' bold '))\n",
    "txt.place(x=700, y=215)\n",
    "\n",
    "lbl2 = tk.Label(window, text=\"Name\",\n",
    "\t\t\t\twidth=20, fg=\"green\", bg=\"white\",\n",
    "\t\t\t\theight=2, font=('times', 15, ' bold '))\n",
    "lbl2.place(x=400, y=300)\n",
    "\n",
    "txt2 = tk.Entry(window, width=20,\n",
    "\t\t\t\tbg=\"white\", fg=\"green\",\n",
    "\t\t\t\tfont=('times', 15, ' bold '))\n",
    "txt2.place(x=700, y=315)\n",
    "\n",
    "# The function below is used for checking\n",
    "# whether the text below is number or not ?\n",
    "\n",
    "\n",
    "def is_number(s):\n",
    "\ttry:\n",
    "\t\tfloat(s)\n",
    "\t\treturn True\n",
    "\texcept ValueError:\n",
    "\t\tpass\n",
    "\n",
    "\ttry:\n",
    "\t\timport unicodedata\n",
    "\t\tunicodedata.numeric(s)\n",
    "\t\treturn True\n",
    "\texcept (TypeError, ValueError):\n",
    "\t\tpass\n",
    "\n",
    "\treturn False\n",
    "# Take Images is a function used for creating\n",
    "# the sample of the images which is used for\n",
    "# training the model. It takes 60 Images of\n",
    "# every new user.\n",
    "\n",
    "\n",
    "def TakeImages():\n",
    "\n",
    "\t# Both ID and Name is used for recognising the Image\n",
    "\tId = (txt.get())\n",
    "\tname = (txt2.get())\n",
    "\n",
    "\t# Checking if the ID is numeric and name is Alphabetical\n",
    "\tif(is_number(Id) and name.isalpha()):\n",
    "\t\t# Opening the primary camera if you want to access\n",
    "\t\t# the secondary camera you can mention the number\n",
    "\t\t# as 1 inside the parenthesis\n",
    "\t\tcam = cv2.VideoCapture(0)\n",
    "\t\t# Specifying the path to haarcascade file\n",
    "\t\tharcascadePath = \"data\\haarcascade_frontalface_default.xml\"\n",
    "\t\t# Creating the classier based on the haarcascade file.\n",
    "\t\tdetector = cv2.CascadeClassifier(harcascadePath)\n",
    "\t\t# Initializing the sample number(No. of images) as 0\n",
    "\t\tsampleNum = 0\n",
    "\t\twhile(True):\n",
    "\t\t\t# Reading the video captures by camera frame by frame\n",
    "\t\t\tret, img = cam.read()\n",
    "\t\t\t# Converting the image into grayscale as most of\n",
    "\t\t\t# the processing is done in gray scale format\n",
    "\t\t\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t\t\t# It converts the images in different sizes\n",
    "\t\t\t# (decreases by 1.3 times) and 5 specifies the\n",
    "\t\t\t# number of times scaling happens\n",
    "\t\t\tfaces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "\t\t\t# For creating a rectangle around the image\n",
    "\t\t\tfor (x, y, w, h) in faces:\n",
    "\t\t\t\t# Specifying the coordinates of the image as well\n",
    "\t\t\t\t# as color and thickness of the rectangle.\n",
    "\t\t\t\t# incrementing sample number for each image\n",
    "\t\t\t\tcv2.rectangle(img, (x, y), (\n",
    "\t\t\t\t\tx + w, y + h), (255, 0, 0), 2)\n",
    "\t\t\t\tsampleNum = sampleNum + 1\n",
    "\t\t\t\t# saving the captured face in the dataset folder\n",
    "\t\t\t\t# TrainingImage as the image needs to be trained\n",
    "\t\t\t\t# are saved in this folder\n",
    "\t\t\t\tcv2.imwrite(\n",
    "\t\t\t\t\t\"TrainingImage\\ \"+name + \".\"+Id + '.' + str(\n",
    "\t\t\t\t\t\tsampleNum) + \".jpg\", gray[y:y + h, x:x + w])\n",
    "\t\t\t\t# display the frame that has been captured\n",
    "\t\t\t\t# and drawn rectangle around it.\n",
    "\t\t\t\tcv2.imshow('frame', img)\n",
    "\t\t\t# wait for 100 milliseconds\n",
    "\t\t\tif cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "\t\t\t\tbreak\n",
    "\t\t\t# break if the sample number is more than 60\n",
    "\t\t\telif sampleNum > 60:\n",
    "\t\t\t\tbreak\n",
    "\t\t# releasing the resources\n",
    "\t\tcam.release()\n",
    "\t\t# closing all the windows\n",
    "\t\tcv2.destroyAllWindows()\n",
    "\t\t# Displaying message for the user\n",
    "\t\tres = \"Images Saved for ID : \" + Id + \" Name : \" + name\n",
    "\t\t# Creating the entry for the user in a csv file\n",
    "\t\trow = [Id, name]\n",
    "\t\twith open('UserDetails\\UserDetails.csv' ,'a+') as csvFile:\n",
    "\t\t\twriter = csv.writer(csvFile)\n",
    "\t\t\t# Entry of the row in csv file\n",
    "\t\t\twriter.writerow(row)\n",
    "\t\tcsvFile.close()\n",
    "\t\tmessage.configure(text=res)\n",
    "\telse:\n",
    "\t\tif(is_number(Id)):\n",
    "\t\t\tres = \"Enter Alphabetical Name\"\n",
    "\t\t\tmessage.configure(text=res)\n",
    "\t\tif(name.isalpha()):\n",
    "\t\t\tres = \"Enter Numeric Id\"\n",
    "\t\t\tmessage.configure(text=res)\n",
    "\n",
    "# Training the images saved in training image folder\n",
    "\n",
    "\n",
    "def TrainImages():\n",
    "\t# Local Binary Pattern Histogram is an Face Recognizer\n",
    "\t# algorithm inside OpenCV module used for training the image dataset\n",
    "\trecognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\t# Specifying the path for HaarCascade file\n",
    "\tharcascadePath = \"data\\haarcascade_frontalface_default.xml\"\n",
    "\t# creating detector for faces\n",
    "\tdetector = cv2.CascadeClassifier(harcascadePath)\n",
    "\t# Saving the detected faces in variables\n",
    "\tfaces, Id = getImagesAndLabels(\"TrainingImage\")\n",
    "\t# Saving the trained faces and their respective ID's\n",
    "\t# in a model named as \"trainer.yml\".\n",
    "\trecognizer.train(faces, np.array(Id))\n",
    "\trecognizer.save(\"TrainingImageLabel\\Trainer.yml\")\n",
    "\t# Displaying the message\n",
    "\tres = \"Image Trained\"\n",
    "\tmessage.configure(text=res)\n",
    "\n",
    "\n",
    "def getImagesAndLabels(path):\n",
    "\t# get the path of all the files in the folder\n",
    "\timagePaths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "\tfaces = []\n",
    "\t# creating empty ID list\n",
    "\tIds = []\n",
    "\t# now looping through all the image paths and loading the\n",
    "\t# Ids and the images saved in the folder\n",
    "\tfor imagePath in imagePaths:\n",
    "\t\t# loading the image and converting it to gray scale\n",
    "\t\tpilImage = Image.open(imagePath).convert('L')\n",
    "\t\t# Now we are converting the PIL image into numpy array\n",
    "\t\timageNp = np.array(pilImage, 'uint8')\n",
    "\t\t# getting the Id from the image\n",
    "\t\tId = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "\t\t# extract the face from the training image sample\n",
    "\t\tfaces.append(imageNp)\n",
    "\t\tIds.append(Id)\n",
    "\treturn faces, Ids\n",
    "# For testing phase\n",
    "\n",
    "\n",
    "def TrackImages():\n",
    "\trecognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\t# Reading the trained model\n",
    "\trecognizer.read(\"TrainingImageLabel\\Trainer.yml\")\n",
    "\tharcascadePath = \"data\\haarcascade_frontalface_default.xml\"\n",
    "\tfaceCascade = cv2.CascadeClassifier(harcascadePath)\n",
    "\t# getting the name from \"userdetails.csv\"\n",
    "\tdf = pd.read_csv(\"UserDetails\\UserDetails.csv\")\n",
    "\tcam = cv2.VideoCapture(0)\n",
    "\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\twhile True:\n",
    "\t\tret, im = cam.read()\n",
    "\t\tgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\t\tfaces = faceCascade.detectMultiScale(gray, 1.2, 5)\n",
    "\t\tfor(x, y, w, h) in faces:\n",
    "\t\t\tcv2.rectangle(im, (x, y), (x + w, y + h), (225, 0, 0), 2)\n",
    "\t\t\tId, conf = recognizer.predict(gray[y:y + h, x:x + w])\n",
    "\t\t\tif(conf < 50):\n",
    "\t\t\t\taa = df.loc[df['Id'] == Id]['Name'].values\n",
    "\t\t\t\ttt = str(Id)+\"-\"+aa\n",
    "\t\t\telse:\n",
    "\t\t\t\tId = 'Unknown'\n",
    "\t\t\t\ttt = str(Id)\n",
    "\t\t\tif(conf > 75):\n",
    "\t\t\t\tnoOfFile = len(os.listdir(\"ImagesUnknown\"))+1\n",
    "\t\t\t\tcv2.imwrite(\"ImagesUnknown\\Image\" +\n",
    "\t\t\t\t\t\t\tstr(noOfFile) + \".jpg\", im[y:y + h, x:x + w])\n",
    "\t\t\tcv2.putText(im, str(tt), (x, y + h),\n",
    "\t\t\t\t\t\tfont, 1, (255, 255, 255), 2)\n",
    "\t\tcv2.imshow('im', im)\n",
    "\t\tif (cv2.waitKey(1) == ord('q')):\n",
    "\t\t\tbreak\n",
    "\tcam.release()\n",
    "\tcv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "takeImg = tk.Button(window, text=\"Sample\",\n",
    "\t\t\t\t\tcommand=TakeImages, fg=\"white\", bg=\"green\",\n",
    "\t\t\t\t\twidth=20, height=3, activebackground=\"Red\",\n",
    "\t\t\t\t\tfont=('times', 15, ' bold '))\n",
    "takeImg.place(x=200, y=500)\n",
    "trainImg = tk.Button(window, text=\"Training\",\n",
    "\t\t\t\t\tcommand=TrainImages, fg=\"white\", bg=\"green\",\n",
    "\t\t\t\t\twidth=20, height=3, activebackground=\"Red\",\n",
    "\t\t\t\t\tfont=('times', 15, ' bold '))\n",
    "trainImg.place(x=500, y=500)\n",
    "trackImg = tk.Button(window, text=\"Testing\",\n",
    "\t\t\t\t\tcommand=TrackImages, fg=\"white\", bg=\"green\",\n",
    "\t\t\t\t\twidth=20, height=3, activebackground=\"Red\",\n",
    "\t\t\t\t\tfont=('times', 15, ' bold '))\n",
    "trackImg.place(x=800, y=500)\n",
    "quitWindow = tk.Button(window, text=\"Quit\",\n",
    "\t\t\t\t\tcommand=window.destroy, fg=\"white\", bg=\"green\",\n",
    "\t\t\t\t\twidth=20, height=3, activebackground=\"Red\",\n",
    "\t\t\t\t\tfont=('times', 15, ' bold '))\n",
    "quitWindow.place(x=1100, y=500)\n",
    "\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4217ee2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mface_recognize.py -d <train_dir> -i <test_image>\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m-i, --test_image =<test_image> Test image\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# importing libraries\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mface_recognition\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdocopt\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Usage:\n",
    "face_recognize.py -d <train_dir> -i <test_image>\n",
    "\n",
    "Options:\n",
    "-h, --help\t\t\t\t\t Show this help\n",
    "-d, --train_dir =<train_dir> Directory with\n",
    "\t\t\t\t\t\t\t\timages for training\n",
    "-i, --test_image =<test_image> Test image\n",
    "\"\"\"\n",
    "\n",
    "# importing libraries\n",
    "import face_recognition\n",
    "import docopt\n",
    "from sklearn import svm\n",
    "import os\n",
    "\n",
    "def face_recognize(dir, test):\n",
    "\t# Training the SVC classifier\n",
    "\t# The training data would be all the\n",
    "\t# face encodings from all the known\n",
    "\t# images and the labels are their names\n",
    "\tencodings = []\n",
    "\tnames = []\n",
    "\n",
    "\t# Training directory\n",
    "\tif dir[-1]!='/':\n",
    "\t\tdir += '/'\n",
    "\ttrain_dir = os.listdir(dir)\n",
    "\n",
    "\t# Loop through each person in the training directory\n",
    "\tfor person in train_dir:\n",
    "\t\tpix = os.listdir(dir + person)\n",
    "\n",
    "\t\t# Loop through each training image for the current person\n",
    "\t\tfor person_img in pix:\n",
    "\t\t\t# Get the face encodings for the face in each image file\n",
    "\t\t\tface = face_recognition.load_image_file(\n",
    "\t\t\t\tdir + person + \"/\" + person_img)\n",
    "\t\t\tface_bounding_boxes = face_recognition.face_locations(face)\n",
    "\n",
    "\t\t\t# If training image contains exactly one face\n",
    "\t\t\tif len(face_bounding_boxes) == 1:\n",
    "\t\t\t\tface_enc = face_recognition.face_encodings(face)[0]\n",
    "\t\t\t\t# Add face encoding for current image\n",
    "\t\t\t\t# with corresponding label (name) to the training data\n",
    "\t\t\t\tencodings.append(face_enc)\n",
    "\t\t\t\tnames.append(person)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(person + \"/\" + person_img + \" can't be used for training\")\n",
    "\n",
    "\t# Create and train the SVC classifier\n",
    "\tclf = svm.SVC(gamma ='scale')\n",
    "\tclf.fit(encodings, names)\n",
    "\n",
    "\t# Load the test image with unknown faces into a numpy array\n",
    "\ttest_image = face_recognition.load_image_file(test)\n",
    "\n",
    "\t# Find all the faces in the test image using the default HOG-based model\n",
    "\tface_locations = face_recognition.face_locations(test_image)\n",
    "\tno = len(face_locations)\n",
    "\tprint(\"Number of faces detected: \", no)\n",
    "\n",
    "\t# Predict all the faces in the test image using the trained classifier\n",
    "\tprint(\"Found:\")\n",
    "\tfor i in range(no):\n",
    "\t\ttest_image_enc = face_recognition.face_encodings(test_image)[i]\n",
    "\t\tname = clf.predict([test_image_enc])\n",
    "\t\tprint(*name)\n",
    "\n",
    "def main():\n",
    "\targs = docopt.docopt(__doc__)\n",
    "\ttrain_dir = args[\"--train_dir\"]\n",
    "\ttest_image = args[\"--test_image\"]\n",
    "\tface_recognize(train_dir, test_image)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad785e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face-recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\bunty\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face-recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\bunty\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face-recognition) (8.1.3)\n",
      "Collecting dlib>=19.7\n",
      "  Using cached dlib-19.24.1.tar.gz (3.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\bunty\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face-recognition) (1.24.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\bunty\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face-recognition) (9.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bunty\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face-recognition) (0.4.6)\n",
      "Installing collected packages: dlib, face-recognition\n",
      "  Running setup.py install for dlib: started\n",
      "  Running setup.py install for dlib: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: dlib is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for dlib did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [9 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\bunty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  running build_ext\n",
      "  \n",
      "  ERROR: CMake must be installed to build dlib\n",
      "  \n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "dlib\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install face-recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
